{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88fb87b0",
   "metadata": {},
   "source": [
    "# Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee5e014",
   "metadata": {},
   "source": [
    "Web Scraping is the process of automatically downloading data displayed by websites to your computer or database. A Web Scraping Software can crawl multiple pages within a website and automate the tedious task of manually copying and pasting the data displayed. \n",
    "\n",
    "With the help of Web scrappers,  you can improve your business’s growth on many fronts, and modern technology gives you many solid reasons as to why you should use web scraping.\n",
    "\n",
    "    1. Monitoring of price: The most important aspect of business management and growth is setting product prices. The prices shouldn’t be so high that it wards customers and you don’t get any orders, and neither should it be too low that it damages your brand name and isn’t profitable to your business model. \n",
    "    2. Possible market trends: We live in a technological idea where we can’t guess how the world will look five years down the road, much like no one could have guessed last year what the world would have looked like right now. But what we can do is make rational choices based on valid research data. Web scraping helps you analyze the research and analytics of possible market trends.\n",
    "    3.Keeping A Watch on Your Competitors: In growing your business, keeping a watch on your competitors; seeing how they are pricing their products and which innovations they are making is important. You can’t grow your business to be the best in the market without knowing what your competitor is up to too. In this regard, web scraping proves to be one of your trusted friends. It helps you scrape all of the data from your competitor’s website and analyze their data. \n",
    "    4.Knowing Your Targeted Audience: If you keep marketing your products to an uninterested audience, then not only you are losing potential customers, but also wasting your money. To know your targeted audience is the first step in growing your business. Web scraping not only helps you to identify your targeted audience but also tells you what products to market to them.\n",
    "    5. Tracking Trends: Where knowing the possible trends is vital for the prospects of your business, keeping track of the ever-changing current trends is necessary too. Only by keeping track of the trends can you satisfy the needs of your customers and make products accordingly. Web scraping makes keeping track of trends easier.\n",
    "    \n",
    "Areas where web scrapping is used:\n",
    "\n",
    "    1.Data Analysis\n",
    "You might want to collect and analyze data related to a specific category from multiple websites. The category might be real estate, automobiles, electronic gadgets, industrial equipment, business contacts, marketing etc.\n",
    "Data is an integral part of any research, be it academic, marketing or scientific. A Web Scraper will help you gather structured data from multiple sources in the Internet with ease.\n",
    "\n",
    "    2. E-Commerce:\n",
    "Web Scraping can be used to periodically extract data of products from various e-commerce websites like Amazon, eBay, Google Shopping etc. Product details like price, description, images, reviews, rating etc. can be easily extracted using a web scraping software.\n",
    "\n",
    "    3. Lead Generation of marketing:\n",
    "A web scraping software can be used to generate leads for marketing. Email and Phone lists for cold outreach can be built by scraping the data from relevant websites. For example, business contact details like phone number and email address can be scraped from yellow pages websites or from Google Maps business listings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2503fc",
   "metadata": {},
   "source": [
    "# Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eb96a2",
   "metadata": {},
   "source": [
    "1. HTML Parsing:\n",
    "    Using socket programming, posting HTTP requests can help one retrieve dynamic as well as static web page information.\n",
    "2. Web scraping Software. \n",
    "    You can make use of a software that can do the web scraping for you. It can automatically retrieve the information off the     web page, convert it into recognizable information, and store it in a local database.\n",
    "3. Text Grepping. \n",
    "    Using Python programming languages or Perl, one can use the UNIX grep command to extract valuable data and information from     web pages.\n",
    "4. DOM Parsing. \n",
    "    In order to dynamically modify or inspect a web page, client-side scripts parse the contents of the web page into a DOM         tree. By embedding a program into the web browser, you can then retrieve the information from the tree.\n",
    "5. Copy-pasting. \n",
    "    The manual human examination and copy-pasting method may sometimes prove irreplaceable. At times, this technique may be the     only practical method to use especially when websites are setup with barriers and machine automation cannot be enabled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbd77a6",
   "metadata": {},
   "source": [
    "# Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fca2f41",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python package for parsing HTML and XML documents. It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping.\n",
    "Beautiful Soup provides simple methods for navigating, searching, and modifying a parse tree in HTML, XML files. It transforms a complex HTML document into a tree of Python objects. It also automatically converts the document to Unicode, so you don't have to think about encodings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd4ebd",
   "metadata": {},
   "source": [
    "# Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3106eacf",
   "metadata": {},
   "source": [
    "Flask is a lightweight framework to build websites. We'll use this to parse our collected data and display it as HTML in a new HTML file. The requests module allows us to send http requests to the website we want to scrape. The first line imports the Flask class and the render_template method from the flask library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9306b26",
   "metadata": {},
   "source": [
    "# Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860792b1",
   "metadata": {},
   "source": [
    "There are many AWS services used in modern age. Some of them explained below\n",
    "1. AWS Elastic Beanstalk:\n",
    "    This AWS service supports running and managing web applications. Elastic Beanstalk allows for the easy deployment of applications from capacity provisioning, load balancing, and auto-scaling to application health monitoring. With its auto-scaling properties, this service simplifies demands in scaling to adjust to the needs of the business. It helps to manage peaks in workloads and traffic with minimum costs. Basically, AWS Elastic Beanstalk is a developer-friendly tool since it manages servers, load balancers, firewalls, and networks simply.\n",
    "2. Amazon EC2 (Elastic Compute Cloud):\n",
    "    Amazon EC2 is one of the fastest-growing cloud computing AWS services, which offers virtual servers to manage any kind of workload. It facilitates the computing infrastructure with the best suitable processors, networking facilities, and storage systems. As a result, it supports adapting to the workloads precisely. Amazon EC2 provides a highly secure, reliable, performing computing infrastructure meeting business demands. \n",
    "3. Amazon S3:\n",
    "    Another popular addition to the AWS services list is Amazon S3, which is an object storage AWS service, which is highly scalable. It mainly helps users to access any quantity of data from anywhere. Here, data is stored in ‘storage classes’ to reduce costs without any extra investment and manage it comfortably.\n",
    "4. AWS Aurora:\n",
    "     It is a MySQL and PostgreSQL compatible relational database with high performance. Believe it or not, it is five times faster than standard MySQL databases. And it allows for automating crucial tasks such as hardware provisioning, database setup and backups, and patching. Amazon Aurora is a distributed, fault-tolerant, self-healing storage system that could scale automatically as per needs. Besides, you can even reduce costs significantly and enhance databases' security, availability, and reliability.\n",
    "5. Amazon DynamoDB:\n",
    "    DynamoDB is a promising addition to this list of AWS services. DynamoDB is a fully managed and serverless NoSQL database AWS service. And it is a fast and flexible database system that provides innovative opportunities to developers at low costs. It gives you single-digit millisecond performance with unlimited throughput and storage. DynamoDB has in-built tools to generate actionable insights, useful analytics, and monitor traffic trends in applications.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c1f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
